{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.4.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device('cuda')\n",
    "#DEVICE = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'views_count' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-8335a2447624>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcamera_matrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mviews_count\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m9\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDEVICE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mpoint3d\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpoint3d_count\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDEVICE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mpoint2d\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcollect_point2d\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDEVICE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mpoint3d_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpoint3d_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDEVICE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mextrinsic_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mviews_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDEVICE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'views_count' is not defined"
     ]
    }
   ],
   "source": [
    "camera_matrix = torch.rand(int(views_count), 9, requires_grad=True, device = DEVICE)\n",
    "point3d = torch.rand(int(point3d_count), 3, requires_grad=True, device = DEVICE)\n",
    "point2d = torch.tensor(collect_point2d, requires_grad=False, device = DEVICE)\n",
    "point3d_index = torch.tensor(point3d_list,dtype=torch.long,requires_grad=False, device = DEVICE)\n",
    "extrinsic_index = torch.tensor(views_list,dtype=torch.long,requires_grad=False, device = DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collect_point2d = []\n",
    "views_list = []\n",
    "point3d_list = []\n",
    "views_count = 0\n",
    "point3d_count = 0\n",
    "uv_count = 0\n",
    "with open('penguinguy_one_angle_matched.db.txt','r') as f:\n",
    "    views_count, point3d_count, uv_count = f.readline().strip().split(' ')\n",
    "    collect_point2d = []\n",
    "    for _ in range(int(uv_count)):\n",
    "        view, p3d, u,v = list(filter(None,f.readline().strip().split(' ')))\n",
    "        collect_point2d.append([float(u),float(v)])\n",
    "        views_list.append(int(view))\n",
    "        point3d_list.append(int(p3d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam([camera_matrix,point3d], lr=0.01) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/kashif/ceres-solver/blob/master/include/ceres/rotation.h#L457\n",
    "def angle_axis_rotate_point(angle_axis, point3d):\n",
    "    # define variable\n",
    "    theta2 = angle_axis * angle_axis \n",
    "    theta2 = theta2.sum(1) #this is equal vector dot\n",
    "    away_zero = theta2.gt(0.0)\n",
    "    near_zero = theta2.lt(0.0)\n",
    "    # away from zero\n",
    "    theta = torch.sqrt(theta2) # some value will be nan in this step\n",
    "    w = angle_axis.t() / theta\n",
    "    w = w.t()\n",
    "    costheta = torch.cos(theta)\n",
    "    sintheta = torch.sin(theta)\n",
    "    w_cross_pt = torch.cross(w,point3d)\n",
    "    w_dot_pt = angle_axis*point3d\n",
    "    w_dot_pt = w_dot_pt.sum(1)\n",
    "    result_farzero = torch.empty(point3d.shape,device =  DEVICE)\n",
    "    for i in range(3):\n",
    "        result_farzero[:,i] = point3d[:,i] * costheta + w_cross_pt[:,i] * sintheta + w[:,i] * (1.0 - costheta) * w_dot_pt\n",
    "    # near zero\n",
    "    w_cross_pt = torch.cross(angle_axis,point3d)\n",
    "    result_nearzero = point3d + w_cross_pt\n",
    "    result = torch.empty(point3d.shape,device =  DEVICE)\n",
    "    for i in range(3):\n",
    "        result[:,i] = result_nearzero[:,i]*near_zero + result_farzero[:,i]*away_zero\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# http://ceres-solver.org/nnls_tutorial.html#bundle-adjustment\n",
    "def ceres_projector(camera_matrix, point3d):\n",
    "    #camera[0,1,2] are the angle-axis rotation.\n",
    "    p = angle_axis_rotate_point(camera_matrix[:,:3], point3d)\n",
    "    # camera[3,4,5] are the translation.\n",
    "    p = p + camera_matrix[:,3:6]\n",
    "    # Compute the center of distortion. The sign change comes from\n",
    "    # the camera model that Noah Snavely's Bundler assumes, whereby\n",
    "    # the camera coordinate system has a negative z axis.\n",
    "    xp = - p[:,0] / p[:,2]\n",
    "    yp = - p[:,1] / p[:,2]\n",
    "    #Apply second and fourth order radial distortion.\n",
    "    l1 = camera_matrix[:,7]\n",
    "    l2 = camera_matrix[:,8]\n",
    "    r2 = xp*xp + yp*yp;\n",
    "    distortion = 1.0 + r2  * (l1 + l2  * r2);\n",
    "    # Compute final projected point position.\n",
    "    focal = camera_matrix[:,6]\n",
    "    predicted_x = focal * distortion * xp;\n",
    "    predicted_y = focal * distortion * yp;\n",
    "    # stack into predicted projection\n",
    "    predicted_projection = torch.stack([predicted_x,predicted_y],dim=1)\n",
    "    return predicted_projection;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10000):\n",
    "    optimizer.zero_grad()\n",
    "    # build camera_matrix\n",
    "    camera_list = camera_matrix[extrinsic_index]\n",
    "    # build point3d matrix\n",
    "    point3d_list = point3d[point3d_index]\n",
    "    # Do projection\n",
    "    projected = ceres_projector(camera_list, point3d_list)\n",
    "    # compare after projection with point2d\n",
    "    uv_difference = torch.pow(point2d - projected,2) \n",
    "    total_loss = uv_difference.sum()\n",
    "    total_loss.backward(retain_graph=True)\n",
    "    optimizer.step()\n",
    "    if i % 10 == 0:\n",
    "        print(\"EPOCH %4d - loss %30.6f\" % (i,total_loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('point3d.npy',point3d.cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point3d.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
