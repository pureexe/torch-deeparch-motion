{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.4.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rotation = torch.zeros(40, 3, 3, requires_grad=True, device = DEVICE)\n",
    "translation = torch.zeros(40, 3, requires_grad=True , device = DEVICE)\n",
    "focal_length = torch.zeros(1, requires_grad=True, device = DEVICE)\n",
    "distrotion =  torch.zeros(1, requires_grad=True, device = DEVICE)\n",
    "camera_px = torch.tensor(460.0, requires_grad=False, device = DEVICE)\n",
    "camera_py = torch.tensor(608.0, requires_grad=False, device = DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "collect_point2d = []\n",
    "views_list = []\n",
    "point3d_list = []\n",
    "views_count = 0\n",
    "point3d_count = 0\n",
    "uv_count = 0\n",
    "with open('penguin_feature_matching.txt','r') as f:\n",
    "    views_count, point3d_count, uv_count = f.readline().strip().split(' ')\n",
    "    collect_point2d = []\n",
    "    for _ in range(int(uv_count)):\n",
    "        view, p3d, u,v = list(filter(None,f.readline().strip().split(' ')))\n",
    "        collect_point2d.append([float(u),float(v)])\n",
    "        views_list.append(int(view))\n",
    "        point3d_list.append(int(p3d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "point3d = torch.rand(int(point3d_count), 3, requires_grad=True, device = DEVICE)\n",
    "point2d = torch.tensor(collect_point2d,requires_grad=False, device = DEVICE)\n",
    "point3d_index = torch.tensor(point3d_list,dtype=torch.long,requires_grad=False, device = DEVICE)\n",
    "extrinsic_index = torch.tensor(views_list,dtype=torch.long,requires_grad=False, device = DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "intrinsic = torch.zeros(3,3, requires_grad=False, device = DEVICE)\n",
    "intrinsic[0,0] = focal_length\n",
    "intrinsic[1,1] = focal_length\n",
    "intrinsic[0,1] = distrotion\n",
    "intrinsic[0,2] = camera_px\n",
    "intrinsic[1,2] = camera_py\n",
    "intrinsic[2,2] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "extrinsic_pad = torch.zeros(int(uv_count),4,4, requires_grad=False, device = DEVICE)\n",
    "extrinsic_pad[:,:,3] = 1\n",
    "extrinsic_pad[:,:3,:3] = rotation[extrinsic_index]\n",
    "extrinsic_pad[:,3,:3] = translation[extrinsic_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "point3d_pad = torch.ones(int(uv_count),4,1, requires_grad=False, device = DEVICE)\n",
    "point3d_pad[:,:3,0] = point3d[point3d_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizer = torch.optim.Adam([rotation, translation, focal_length,distrotion,point3d], lr=0.01)\n",
    "# use per parameter learning rate\n",
    "optimizer = torch.optim.Adam([\n",
    "    {'params':focal_length, 'lr':1},\n",
    "    {'params':rotation},\n",
    "    {'params':translation},\n",
    "    {'params':distrotion},\n",
    "    {'params':point3d},\n",
    "], lr=0.01) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 0 - loss 1085168768.000000\n",
      "EPOCH 100 - loss 1085168768.000000\n",
      "EPOCH 200 - loss 1085168768.000000\n",
      "EPOCH 300 - loss 1085168768.000000\n",
      "EPOCH 400 - loss 1085168768.000000\n",
      "EPOCH 500 - loss 1085168768.000000\n",
      "EPOCH 600 - loss 1085168768.000000\n",
      "EPOCH 700 - loss 1085168768.000000\n",
      "EPOCH 800 - loss 1085168768.000000\n",
      "EPOCH 900 - loss 1085168768.000000\n",
      "EPOCH 1000 - loss 1085168768.000000\n",
      "EPOCH 1100 - loss 1085168768.000000\n",
      "EPOCH 1200 - loss 1085168768.000000\n",
      "EPOCH 1300 - loss 1085168768.000000\n",
      "EPOCH 1400 - loss 1085168768.000000\n",
      "EPOCH 1500 - loss 1085168768.000000\n",
      "EPOCH 1600 - loss 1085168768.000000\n",
      "EPOCH 1700 - loss 1085168768.000000\n",
      "EPOCH 1800 - loss 1085168768.000000\n",
      "EPOCH 1900 - loss 1085168768.000000\n",
      "EPOCH 2000 - loss 1085168768.000000\n",
      "EPOCH 2100 - loss 1085168768.000000\n",
      "EPOCH 2200 - loss 1085168768.000000\n",
      "EPOCH 2300 - loss 1085168768.000000\n",
      "EPOCH 2400 - loss 1085168768.000000\n",
      "EPOCH 2500 - loss 1085168768.000000\n",
      "EPOCH 2600 - loss 1085168768.000000\n",
      "EPOCH 2700 - loss 1085168768.000000\n",
      "EPOCH 2800 - loss 1085168768.000000\n",
      "EPOCH 2900 - loss 1085168768.000000\n",
      "EPOCH 3000 - loss 1085168768.000000\n",
      "EPOCH 3100 - loss 1085168768.000000\n",
      "EPOCH 3200 - loss 1085168768.000000\n",
      "EPOCH 3300 - loss 1085168768.000000\n",
      "EPOCH 3400 - loss 1085168768.000000\n",
      "EPOCH 3500 - loss 1085168768.000000\n",
      "EPOCH 3600 - loss 1085168768.000000\n",
      "EPOCH 3700 - loss 1085168768.000000\n",
      "EPOCH 3800 - loss 1085168768.000000\n",
      "EPOCH 3900 - loss 1085168768.000000\n",
      "EPOCH 4000 - loss 1085168768.000000\n",
      "EPOCH 4100 - loss 1085168768.000000\n",
      "EPOCH 4200 - loss 1085168768.000000\n",
      "EPOCH 4300 - loss 1085168768.000000\n",
      "EPOCH 4400 - loss 1085168768.000000\n",
      "EPOCH 4500 - loss 1085168768.000000\n",
      "EPOCH 4600 - loss 1085168768.000000\n",
      "EPOCH 4700 - loss 1085168768.000000\n",
      "EPOCH 4800 - loss 1085168768.000000\n",
      "EPOCH 4900 - loss 1085168768.000000\n",
      "EPOCH 5000 - loss 1085168768.000000\n",
      "EPOCH 5100 - loss 1085168768.000000\n",
      "EPOCH 5200 - loss 1085168768.000000\n",
      "EPOCH 5300 - loss 1085168768.000000\n",
      "EPOCH 5400 - loss 1085168768.000000\n",
      "EPOCH 5500 - loss 1085168768.000000\n",
      "EPOCH 5600 - loss 1085168768.000000\n",
      "EPOCH 5700 - loss 1085168768.000000\n",
      "EPOCH 5800 - loss 1085168768.000000\n",
      "EPOCH 5900 - loss 1085168768.000000\n",
      "EPOCH 6000 - loss 1085168768.000000\n",
      "EPOCH 6100 - loss 1085168768.000000\n",
      "EPOCH 6200 - loss 1085168768.000000\n",
      "EPOCH 6300 - loss 1085168768.000000\n",
      "EPOCH 6400 - loss 1085168768.000000\n",
      "EPOCH 6500 - loss 1085168768.000000\n",
      "EPOCH 6600 - loss 1085168768.000000\n",
      "EPOCH 6700 - loss 1085168768.000000\n",
      "EPOCH 6800 - loss 1085168768.000000\n",
      "EPOCH 6900 - loss 1085168768.000000\n",
      "EPOCH 7000 - loss 1085168768.000000\n",
      "EPOCH 7100 - loss 1085168768.000000\n",
      "EPOCH 7200 - loss 1085168768.000000\n",
      "EPOCH 7300 - loss 1085168768.000000\n",
      "EPOCH 7400 - loss 1085168768.000000\n",
      "EPOCH 7500 - loss 1085168768.000000\n",
      "EPOCH 7600 - loss 1085168768.000000\n",
      "EPOCH 7700 - loss 1085168768.000000\n",
      "EPOCH 7800 - loss 1085168768.000000\n",
      "EPOCH 7900 - loss 1085168768.000000\n",
      "EPOCH 8000 - loss 1085168768.000000\n",
      "EPOCH 8100 - loss 1085168768.000000\n",
      "EPOCH 8200 - loss 1085168768.000000\n",
      "EPOCH 8300 - loss 1085168768.000000\n",
      "EPOCH 8400 - loss 1085168768.000000\n",
      "EPOCH 8500 - loss 1085168768.000000\n",
      "EPOCH 8600 - loss 1085168768.000000\n",
      "EPOCH 8700 - loss 1085168768.000000\n",
      "EPOCH 8800 - loss 1085168768.000000\n",
      "EPOCH 8900 - loss 1085168768.000000\n",
      "EPOCH 9000 - loss 1085168768.000000\n",
      "EPOCH 9100 - loss 1085168768.000000\n",
      "EPOCH 9200 - loss 1085168768.000000\n",
      "EPOCH 9300 - loss 1085168768.000000\n",
      "EPOCH 9400 - loss 1085168768.000000\n",
      "EPOCH 9500 - loss 1085168768.000000\n",
      "EPOCH 9600 - loss 1085168768.000000\n",
      "EPOCH 9700 - loss 1085168768.000000\n",
      "EPOCH 9800 - loss 1085168768.000000\n",
      "EPOCH 9900 - loss 1085168768.000000\n"
     ]
    }
   ],
   "source": [
    "for i in range(10000):\n",
    "    optimizer.zero_grad()\n",
    "    # Do projection\n",
    "    extrinsic_pad_point = torch.matmul(extrinsic_pad,point3d_pad)\n",
    "    extrinsic_pad_point = extrinsic_pad_point[:,:3,:]\n",
    "    projected_point = torch.matmul(intrinsic,extrinsic_pad_point[:,:3,:])\n",
    "    projected_point = projected_point[:,:,0]\n",
    "    uv_map = torch.empty(int(uv_count),2, device = DEVICE)\n",
    "    uv_map[:,0] = projected_point[:,0] / projected_point[:,2]\n",
    "    uv_map[:,1] = projected_point[:,1] / projected_point[:,2]\n",
    "    # compare after projection with point2d\n",
    "    uv_difference = torch.pow(point2d - uv_map, 2)\n",
    "    total_loss = uv_difference.sum()\n",
    "    total_loss.backward(retain_graph=True)\n",
    "    optimizer.step()\n",
    "    if i % 100 == 0:\n",
    "        print(\"EPOCH %d - loss %f\" % (i,total_loss.item()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
